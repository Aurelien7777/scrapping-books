# üìö Books Online ‚Äî Syst√®me de surveillance des prix (version b√™ta)

## 1. Contexte et objectif du projet
Ce projet a √©t√© d√©velopp√© dans le cadre du parcours **OpenClassrooms ‚Äî Utilisez les bases de Python pour l'analyse de march√©**.

### Mission
Vous √™tes **analyste marketing chez Books Online**, une librairie en ligne sp√©cialis√©e dans les livres d'occasion.  
Afin de gagner du temps dans la surveillance des prix des concurrents, ce projet met en place un **scraper Python** pour le site [Books to Scrape](https://books.toscrape.com/), permettant d‚Äôextraire automatiquement les donn√©es suivantes :

- URL de la page produit
- UPC (Universal Product Code)
- Titre du livre
- Prix TTC et HT
- Disponibilit√©
- Description
- Cat√©gorie
- Note (Review Rating)
- URL de l‚Äôimage

Le script :
- **Collecte** les donn√©es pour toutes les cat√©gories du site
- **Enregistre** un fichier CSV par cat√©gorie dans le dossier `COLLECT_DATA`
- **T√©l√©charge** toutes les images dans un dossier sp√©cifique par cat√©gorie

‚ö†Ô∏è **Les fichiers CSV et images ne doivent pas √™tre versionn√©s sur GitHub** ‚Äî ils sont g√©n√©r√©s √† l‚Äôex√©cution.


## 2. Instructions d‚Äôinstallation

### Pr√©requis
- **Python** ‚â• 3.8
- Connexion Internet
- Environnement virtuel recommand√© (venv ou conda)

### Installation des d√©pendances
1. Cloner le projet :

git clone https://github.com/Aurelien7777/scrapping-books.git
cd scrapping-books


2. Cr√©er et activer un environnement virtuel :

python -m venv venv
source venv/bin/activate      # macOS / Linux
venv\Scripts\activate         # Windows


3. Installer les d√©pendances

pip install -r requirements.txt


## 3. Comment ex√©cuter le script
Lancer le script principal depuis la racine du projet :
python script.py

Le script :

Cr√©e un dossier COLLECT_DATA contenant un fichier CSV par cat√©gorie.

Cr√©e un dossier d‚Äôimages par cat√©gorie (ex. IMAGE_CATEGORY_travel).

T√©l√©charge et enregistre toutes les donn√©es et images localement.


## 4. Explication des fichiers importants

- script.py	= Script principal contenant le code de scraping
- requirements.txt	= Liste des d√©pendances n√©cessaires au projet
- .gitignore	=  Fichier pour exclure les fichiers/dossiers non suivis (CSV, images, venv, etc.)
- COLLECT_DATA/ (g√©n√©r√©)	=  Contient les CSV par cat√©gorie
- IMAGE_CATEGORY_<nom_cat√©gorie>/ (g√©n√©r√©)	=  Contient les images par cat√©gorie
- README.md	=  Documentation du projet

## 5. Contact / Ressources pour aide

Auteur : Amorin Aur√©lien
E-mail : Aur√©lien.amorin@gmail.com

Ressources utilis√©es :

- Documentation Python

- Requests

- BeautifulSoup4

- Books to Scrape






